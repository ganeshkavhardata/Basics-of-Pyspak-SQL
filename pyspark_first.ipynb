{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbc7e8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/15 10:41:49 WARN Utils: Your hostname, Ganeshs-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 192.168.153.137 instead (on interface en0)\n",
      "24/06/15 10:41:49 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/06/15 10:41:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pyspark/context.py:317: FutureWarning: Python 3.7 support is deprecated in Spark 3.4.\n",
      "  warnings.warn(\"Python 3.7 support is deprecated in Spark 3.4.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark=SparkSession.builder.appName(\"codedbyganesh\").getOrCreate()\n",
    "\n",
    "# Get the SparkContext from the SparkSession\n",
    "sc=spark.sparkContext\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afda9870",
   "metadata": {},
   "source": [
    "\n",
    "## code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48249c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create DataFrame\n",
    "data = [('James','','Smith','1991-04-01','M',3000),\n",
    "  ('Michael','Rose','','2000-05-19','M',4000),\n",
    "  ('Robert','','Williams','1978-09-05','M',4000),\n",
    "  ('Maria','Anne','Jones','1967-12-01','F',4000),\n",
    "  ('Jen','Mary','Brown','1980-02-17','F',-1)\n",
    "]\n",
    "\n",
    "columns = [\"firstname\",\"middlename\",\"lastname\",\"dob\",\"gender\",\"salary\"]\n",
    "df = spark.createDataFrame(data=data, schema = columns)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4de1d97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+----------+\n",
      "|    _c0|       _c1|       _c2|\n",
      "+-------+----------+----------+\n",
      "|flights|      date|passengers|\n",
      "|flight1|04-03-2016|       360|\n",
      "|flight1|14-03-2016|       342|\n",
      "|flight2|14-03-2016|       406|\n",
      "|flight3|06-03-2016|       396|\n",
      "|flight4|26-09-2016|       420|\n",
      "|flight1|09-03-2016|       472|\n",
      "|flight2|22-09-2016|       548|\n",
      "|flight3|27-07-2016|       559|\n",
      "|flight4|08-04-2016|       463|\n",
      "|flight1|29-12-2016|       407|\n",
      "|flight2|22-07-2016|       362|\n",
      "|flight3|15-10-2016|       405|\n",
      "|flight4|16-05-2016|       420|\n",
      "|flight1|30-10-2016|       472|\n",
      "|flight2|04-01-2016|       548|\n",
      "|flight3|04-01-2016|       559|\n",
      "|flight4|13-11-2016|       420|\n",
      "|flight1|01-03-2016|       472|\n",
      "|flight2|23-09-2016|       548|\n",
      "+-------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=spark.read.csv(\"/Users/ganesh/Downloads/airtravel.csv\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "876c95f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa845d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01dfc8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+----------+\n",
      "|    _c0|       _c1|       _c2|\n",
      "+-------+----------+----------+\n",
      "|flights|      date|passengers|\n",
      "|flight1|04-03-2016|       360|\n",
      "|flight1|14-03-2016|       342|\n",
      "|flight2|14-03-2016|       406|\n",
      "|flight3|06-03-2016|       396|\n",
      "|flight4|26-09-2016|       420|\n",
      "|flight1|09-03-2016|       472|\n",
      "|flight2|22-09-2016|       548|\n",
      "|flight3|27-07-2016|       559|\n",
      "|flight4|08-04-2016|       463|\n",
      "|flight1|29-12-2016|       407|\n",
      "|flight2|22-07-2016|       362|\n",
      "|flight3|15-10-2016|       405|\n",
      "|flight4|16-05-2016|       420|\n",
      "|flight1|30-10-2016|       472|\n",
      "|flight2|04-01-2016|       548|\n",
      "|flight3|04-01-2016|       559|\n",
      "|flight4|13-11-2016|       420|\n",
      "|flight1|01-03-2016|       472|\n",
      "|flight2|23-09-2016|       548|\n",
      "+-------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from df\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d989d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "|    _c0|       _c1|\n",
      "+-------+----------+\n",
      "|flights|      date|\n",
      "|flight1|04-03-2016|\n",
      "|flight1|14-03-2016|\n",
      "|flight2|14-03-2016|\n",
      "|flight3|06-03-2016|\n",
      "|flight4|26-09-2016|\n",
      "|flight1|09-03-2016|\n",
      "|flight2|22-09-2016|\n",
      "|flight3|27-07-2016|\n",
      "|flight4|08-04-2016|\n",
      "|flight1|29-12-2016|\n",
      "|flight2|22-07-2016|\n",
      "|flight3|15-10-2016|\n",
      "|flight4|16-05-2016|\n",
      "|flight1|30-10-2016|\n",
      "|flight2|04-01-2016|\n",
      "|flight3|04-01-2016|\n",
      "|flight4|13-11-2016|\n",
      "|flight1|01-03-2016|\n",
      "|flight2|23-09-2016|\n",
      "+-------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select _c0,_c1 from df\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24e3ce3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+---+\n",
      "|    _c0|       _c1|_c2|\n",
      "+-------+----------+---+\n",
      "|flight1|04-03-2016|360|\n",
      "|flight1|14-03-2016|342|\n",
      "|flight1|09-03-2016|472|\n",
      "|flight1|29-12-2016|407|\n",
      "|flight1|30-10-2016|472|\n",
      "|flight1|01-03-2016|472|\n",
      "|flight1|20-12-2016|472|\n",
      "|flight2|14-03-2016|406|\n",
      "|flight2|22-09-2016|548|\n",
      "|flight2|22-07-2016|362|\n",
      "|flight2|04-01-2016|548|\n",
      "|flight2|23-09-2016|548|\n",
      "|flight2|26-02-2016|548|\n",
      "|flight3|06-03-2016|396|\n",
      "|flight3|27-07-2016|559|\n",
      "|flight3|15-10-2016|405|\n",
      "|flight3|04-01-2016|559|\n",
      "|flight3|22-03-2016|559|\n",
      "|flight3|01-01-2016|559|\n",
      "|flight4|26-09-2016|420|\n",
      "+-------+----------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from df order by _c0\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f7a95d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+---+\n",
      "|    _c0|       _c1|_c2|\n",
      "+-------+----------+---+\n",
      "|flight1|09-03-2016|472|\n",
      "|flight2|22-09-2016|548|\n",
      "|flight3|27-07-2016|559|\n",
      "|flight4|08-04-2016|463|\n",
      "|flight1|30-10-2016|472|\n",
      "|flight2|04-01-2016|548|\n",
      "|flight3|04-01-2016|559|\n",
      "|flight1|01-03-2016|472|\n",
      "|flight2|23-09-2016|548|\n",
      "|flight3|22-03-2016|559|\n",
      "|flight1|20-12-2016|472|\n",
      "|flight2|26-02-2016|548|\n",
      "|flight3|01-01-2016|559|\n",
      "+-------+----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from df where _c2>450 and _c2<560\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cce7561e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+---+\n",
      "|    _c0|       _c1|_c2|\n",
      "+-------+----------+---+\n",
      "|flight3|06-03-2016|396|\n",
      "|flight3|27-07-2016|559|\n",
      "|flight3|15-10-2016|405|\n",
      "|flight3|04-01-2016|559|\n",
      "|flight3|22-03-2016|559|\n",
      "|flight3|01-01-2016|559|\n",
      "+-------+----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from df where _c0 like('flight3%')\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53717a5",
   "metadata": {},
   "source": [
    "### LIKE Operator in SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6079d1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"select * from df where _c0 like('flight3%')\").show() #starting with flight3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "13cd0655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+---+\n",
      "|    _c0|       _c1|_c2|\n",
      "+-------+----------+---+\n",
      "|flight3|06-03-2016|396|\n",
      "|flight3|27-07-2016|559|\n",
      "|flight3|15-10-2016|405|\n",
      "|flight3|04-01-2016|559|\n",
      "|flight3|22-03-2016|559|\n",
      "|flight3|01-01-2016|559|\n",
      "+-------+----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from df where _c0 like('%3')\").show() #ending with 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5f3344fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+----------+\n",
      "|    _c0|       _c1|       _c2|\n",
      "+-------+----------+----------+\n",
      "|flights|      date|passengers|\n",
      "|flight1|04-03-2016|       360|\n",
      "|flight1|14-03-2016|       342|\n",
      "|flight2|14-03-2016|       406|\n",
      "|flight3|06-03-2016|       396|\n",
      "|flight4|26-09-2016|       420|\n",
      "|flight1|09-03-2016|       472|\n",
      "|flight2|22-09-2016|       548|\n",
      "|flight3|27-07-2016|       559|\n",
      "|flight4|08-04-2016|       463|\n",
      "|flight1|29-12-2016|       407|\n",
      "|flight2|22-07-2016|       362|\n",
      "|flight3|15-10-2016|       405|\n",
      "|flight4|16-05-2016|       420|\n",
      "|flight1|30-10-2016|       472|\n",
      "|flight2|04-01-2016|       548|\n",
      "|flight3|04-01-2016|       559|\n",
      "|flight4|13-11-2016|       420|\n",
      "|flight1|01-03-2016|       472|\n",
      "|flight2|23-09-2016|       548|\n",
      "+-------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from df where _c0 like('%fli%')\").show() #contein in middle characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ae246aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+----------+\n",
      "|    _c0|       _c1|       _c2|\n",
      "+-------+----------+----------+\n",
      "|flights|      date|passengers|\n",
      "|flight1|04-03-2016|       360|\n",
      "|flight1|14-03-2016|       342|\n",
      "|flight2|14-03-2016|       406|\n",
      "|flight3|06-03-2016|       396|\n",
      "|flight4|26-09-2016|       420|\n",
      "|flight1|09-03-2016|       472|\n",
      "|flight2|22-09-2016|       548|\n",
      "|flight3|27-07-2016|       559|\n",
      "|flight4|08-04-2016|       463|\n",
      "|flight1|29-12-2016|       407|\n",
      "|flight2|22-07-2016|       362|\n",
      "|flight3|15-10-2016|       405|\n",
      "|flight4|16-05-2016|       420|\n",
      "|flight1|30-10-2016|       472|\n",
      "|flight2|04-01-2016|       548|\n",
      "|flight3|04-01-2016|       559|\n",
      "|flight4|13-11-2016|       420|\n",
      "|flight1|01-03-2016|       472|\n",
      "|flight2|23-09-2016|       548|\n",
      "+-------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from df where _c0 like('__i%')\").show() #contein i at 3rd position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7d94db3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+---+\n",
      "|    _c0|       _c1|_c2|\n",
      "+-------+----------+---+\n",
      "|flight3|27-07-2016|559|\n",
      "|flight3|04-01-2016|559|\n",
      "|flight3|22-03-2016|559|\n",
      "|flight3|01-01-2016|559|\n",
      "+-------+----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from df where _c2 like('%55%')\").show() #contein 55 twice in column content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36608e7b",
   "metadata": {},
   "source": [
    "### Not Like Operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c9050236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+----------+\n",
      "|    _c0|       _c1|       _c2|\n",
      "+-------+----------+----------+\n",
      "|flights|      date|passengers|\n",
      "|flight1|04-03-2016|       360|\n",
      "|flight1|14-03-2016|       342|\n",
      "|flight2|14-03-2016|       406|\n",
      "|flight3|06-03-2016|       396|\n",
      "|flight4|26-09-2016|       420|\n",
      "|flight1|09-03-2016|       472|\n",
      "|flight2|22-09-2016|       548|\n",
      "|flight3|27-07-2016|       559|\n",
      "|flight4|08-04-2016|       463|\n",
      "|flight1|29-12-2016|       407|\n",
      "|flight2|22-07-2016|       362|\n",
      "|flight3|15-10-2016|       405|\n",
      "|flight4|16-05-2016|       420|\n",
      "|flight1|30-10-2016|       472|\n",
      "|flight2|04-01-2016|       548|\n",
      "|flight3|04-01-2016|       559|\n",
      "|flight4|13-11-2016|       420|\n",
      "|flight1|01-03-2016|       472|\n",
      "|flight2|23-09-2016|       548|\n",
      "+-------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from df where _c0 not like('%l')\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f39cf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89945ab2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378fba8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d061d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570955f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
